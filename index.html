<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <title>MediaPipe Object Detector — mobile</title>
  <!-- MediaPipe Tasks (Object Detector) bundle via CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js" crossorigin="anonymous"></script>
  <style>
    html,body{height:100%;margin:0;background:#000;color:#fff;font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial}
    .wrapper{position:relative;width:100%;height:100%;overflow:hidden;display:flex;align-items:center;justify-content:center}
    video{position:relative;object-fit:cover;width:100%;height:100%;transform:scaleX(-1);} /* mirror for user-facing camera; environment may not need mirror */
    canvas{position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:none}
    #controls{position:absolute;left:8px;top:8px;z-index:20}
    button{padding:8px 12px;border-radius:8px;border:none;background:#1a73e8;color:white}
  </style>
</head>
<body>
  <div class="wrapper">
    <video id="video" playsinline autoplay muted></video>
    <canvas id="overlay"></canvas>
    <div id="controls">
      <button id="startBtn">Iniciar cámara</button>
    </div>
  </div>

  <script>
    // Basado en la guía oficial de MediaPipe Object Detector (Tasks API).
    // Fuente y referencia: https://ai.google.dev/edge/mediapipe/solutions/vision/object_detector/web_js

    const startBtn = document.getElementById('startBtn');
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });

    let detector = null;
    let running = false;

    async function initDetector() {
      // Crea FilesetResolver para Vision Tasks (usa la carpeta wasm del paquete CDN)
      const vision = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
      );

      detector = await ObjectDetector.createFromOptions(vision, {
        baseOptions: {
          // modelo preentrenado alojado por MediaPipe
          modelAssetPath: 'https://storage.googleapis.com/mediapipe-tasks/object_detector/efficientdet_lite0_uint8.tflite'
        },
        scoreThreshold: 0.5,
        runningMode: 'VIDEO'
      });
    }

    async function startCamera() {
      // Preferir cámara trasera en móviles
      const constraints = { video: { facingMode: { ideal: 'environment' } }, audio: false };
      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        await video.play();
        resizeCanvasToVideo();
        window.addEventListener('resize', resizeCanvasToVideo);
        running = true;
        requestAnimationFrame(renderLoop);
      } catch (e) {
        alert('No se pudo acceder a la cámara: ' + e.message);
        console.error(e);
      }
    }

    function resizeCanvasToVideo() {
      // Ajusta canvas a las dimensiones reales en pantalla
      const rect = video.getBoundingClientRect();
      canvas.width = rect.width;
      canvas.height = rect.height;
      // Si se usa CSS transform de espejo para video, no necesitamos reflejar el canvas
    }

    function drawBoxAndLine(bbox, label, score) {
      // bbox: {originX, originY, width, height} en coordenadas del video "natural" (según docs)
      // Necesitamos mapear al tamaño en pantalla
      const videoRect = video.getBoundingClientRect();
      const scaleX = videoRect.width / video.videoWidth;
      const scaleY = videoRect.height / video.videoHeight;

      const x = bbox.originX * scaleX;
      const y = bbox.originY * scaleY;
      const w = bbox.width * scaleX;
      const h = bbox.height * scaleY;

      // centro del objeto
      const cx = x + w / 2;
      const cy = y + h / 2;

      // punto abajo-centro de la cámara (en coordenadas canvas)
      const bottomCenterX = canvas.width / 2;
      const bottomCenterY = canvas.height; // borde inferior

      // dibujar caja
      ctx.lineWidth = Math.max(2, Math.round(2 * (canvas.width/360)));
      ctx.strokeStyle = 'lime';
      ctx.strokeRect(x, y, w, h);

      // etiqueta
      ctx.font = '18px sans-serif';
      ctx.fillStyle = 'lime';
      const text = `${label} ${Math.round(score*100)}%`;
      ctx.fillText(text, x + 4, y > 20 ? y - 6 : y + 18);

      // dibujar línea desde centro del objeto hasta abajo-centro
      ctx.beginPath();
      ctx.moveTo(cx, cy);
      ctx.lineTo(bottomCenterX, bottomCenterY);
      ctx.lineWidth = 3;
      ctx.strokeStyle = 'rgba(255,0,0,0.95)';
      ctx.stroke();

      // dibujar punto final pequeño
      ctx.beginPath();
      ctx.arc(bottomCenterX, bottomCenterY - 6, 6, 0, Math.PI*2);
      ctx.fillStyle = 'rgba(255,0,0,0.95)';
      ctx.fill();
    }

    async function renderLoop(now) {
      if (!running || !detector) return requestAnimationFrame(renderLoop);

      // Asegurarse que el video tiene dimensiones válidas
      if (video.readyState < 2) return requestAnimationFrame(renderLoop);

      // Limpieza del canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      try {
        // detectForVideo devuelve DetectionResult con .detections (ver docs)
        const detections = detector.detectForVideo(video, performance.now());
        if (detections && detections.detections) {
          for (const d of detections.detections) {
            const cat = d.categories && d.categories[0] ? d.categories[0].categoryName : 'obj';
            const score = d.categories && d.categories[0] ? d.categories[0].score : 0;
            drawBoxAndLine(d.boundingBox, cat, score);
          }
        }
      } catch (e) {
        // Si el detector da errores no bloqueantes, los registramos
        console.error('Detection error:', e);
      }

      requestAnimationFrame(renderLoop);
    }

    // Inicialización en clic para evitar bloqueos de autoplay y permisos en móvil
    startBtn.addEventListener('click', async () => {
      startBtn.disabled = true;
      startBtn.innerText = 'Inicializando...';
      try {
        if (!detector) await initDetector();
        await startCamera();
        startBtn.style.display = 'none';
      } catch (e) {
        console.error(e);
        startBtn.disabled = false;
        startBtn.innerText = 'Iniciar cámara';
      }
    });

    // Si quieres forzar espejo/desespejo dependiendo de cámara, puedes hacerlo aquí.
  </script>
</body>
</html>
